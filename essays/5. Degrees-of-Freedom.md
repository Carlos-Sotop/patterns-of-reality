In 1788, the French mathematician Joseph-Louis Lagrange published *Mécanique analytique*. He wanted to describe motion without describing every part. 

At the time, mechanics meant drawing machines, labeling every joint, writing a force balance for every bolt. It worked fine for falling apples and rolling balls, but it failed miserably for clocks, bridges, and linkages and all the kinds of systems the *Industrial Revolution* was beginning to care about.

Lagrange saw that physical systems are compressible. That is, a machine may have hundreds of parts, but only a few things actually change independently. Everything else is dragged along by constraints, repeating the same information in different coordinates.

Instead of asking where every component sits in absolute space, Lagrange asked a more economical question: what is the smallest set of independent variables needed to specify the system’s state?.

That irreducible description is what he called the *system’s degrees of freedom*. Everything beyond it is *decompression*, useful for visualization, perhaps, but unnecessary for the physics.

A rigid body moving freely in three-dimensional space has six degrees of freedom. Three describe translation, its position along the xyz axes of a chosen reference frame. The other three describe rotation, how the body is oriented relative to those axes, independent of where it is.

A light switch has one degree of freedom, as it moves along a single allowed path. A door on a hinge does the same: no matter how large the door, its motion is compressed into one rotation.

Then come articulated systems. A human hand is not one object but many linked together. Each finger has multiple joints, and each joint contributes its own degree of freedom. The degrees of freedom add, but the configurations they allow multiply. Ten joints with only a few possible positions each already generate more configurations than can be consciously enumerated.

The most complex man-made machines take this logic to extremes. A modern computer contains billions of independently switching elements. Each transistor has a single degree of freedom and only two states. But because they are independent, the total number of possible states grows exponentially. The system becomes too large to enumerate and can only be navigated.

Beyond machines lie fields. In physics, a field assigns a value to every point in space. Not one object, not many parts, but an independent variable defined everywhere. The degrees of freedom are no longer counted in units or billions, but scale with space itself. The resulting state space is effectively unbounded, the highest-dimensional framework humans have ever used.

## The leap from machines to humans.

In 1956, the British psychiatrist W. Ross Ashby published *An Introduction to Cybernetics*. Ashby studied regulation in biological systems: how organisms maintain stability while the world around them changes. This process is now called *homeostasis*: the ability of a system to keep key variables within bounds despite external disturbances.

To formalize this, Ashby introduced the concept of *variety*: the number of distinct states a system can occupy. In modern terms, variety is degrees of freedom made countable, the size of a system’s state space.

From this, Ashby derived what became known as the Law of Requisite Variety:

**Only variety can absorb variety.**

If the environment can disturb a system in more independent ways than the regulator can counter, regulation fails by definition. Stability can be restored in only two ways: by expanding the regulator’s own repertoire of responses, giving it more internal ways to act, or by compressing the environment, reducing the number of independent variables the organism must internally control, such as temperature, osmotic pressure, oxygen availability, or pathogen exposure.

## The leap from humans to society.

Political systems look like they decay morally. In reality, many of them fail mechanically.

A new regime often begins with a strong unifying condition: a mission, a threat, or both. Early on, society has fewer active degrees of freedom, and so control is easier.

Over time, that unifier fades as the mission is achieved or the threat disappears. Factions begin to form, and incentives start diverging, and so the number of independent axes along which society can vary increases.

The governing structure, however, remains largely fixed in practice. Formal texts may evolve, but the bureaucratic primitives through which regulation acts change slowly. As society gains degrees of freedom, new rules do not add dimensionality to the controller, they stack more constraints on the same low-dimensional machinery. What once regulated a simple system is now applied, ever more forcefully, to a system that no longer fits inside it.

At that point, regulation does not adapt, but tightens further, and each additional rule further constrains a space it can no longer span, turning governance into a rigid straitjacket rather than a stabilizing mechanism.

From there, two structural common paths follow:

**1) Withdraw regulation at that layer**: allow coordination, experimentation, and adaptation to occur without a centralized controller that can no longer match the system’s dimensionality.

**2) Reduce society’s degrees of freedom**: coercion, censorship, financial control, surveillance.

The second path is why decaying regimes become authoritarian. Not always out of ideology, but out of mechanical desperation: collapsing reality back into something governable.

This is why mission renewal matters. A mission is not just motivation, it is dimensional compression, as it collapses disagreements into a single shared axis of truth / action.

When a country declares itself “the crypto capital of the world,” it is not solving every disagreement, it is narrowing them. For a time, legal, economic, and cultural variance is subordinated to one organizing objective, and governability improves not because control improved, but because the problem space shrank.

## Why the Enlightenment happened.

The Enlightenment is often described as "better ideas." But structurally, it was an institutional adaptation to a higher-dimensional world.

The printing press didn't just spread information, but it expanded the degrees of freedom in what people could know, believe, and coordinate around. Pre-print societies could maintain coherence through centralized religious and political authority. Post-print, that became mechanically impossible. Too many independent sources of information, too many competing narratives, too much variance to suppress.

The Enlightenment institutions responded by increasing the dimensionality of governance itself:

- Separation of powers added internal degrees of freedom, different branches could act independently.
- Rule of law standardized responses across more cases without requiring centralized judgment each time.
- Rights constrained coercion as a control shortcut, preventing the easy collapse back to suppression.
- Free speech tolerated higher informational variety without permanent suppression.

The framework survived for centuries not because it was morally superior (though it may have been), but because it was a better dimensional fit for print-era society. It could regulate a higher-dimensional system without collapsing it.

Now we face another transition. The internet, AI, and cryptography expand degrees of freedom again, in what people can know, create, coordinate around, and transact. The question is whether existing institutions can adapt, or whether they'll attempt the second path: dimensional compression through control.

## Why non-delegation matters.

Delegation is the act of giving control over a function to an intermediary. It compresses complexity, you don't need to understand banking, just trust your bank, but it also collapses your degrees of freedom.

If your money exists as a database entry at an institution, your action space is whatever that institution permits. In normal times, this is convenient, but in crisis, it becomes a tool for coercion.

This is why modern control often looks administrative rather than violent:

- Deplatforming.
- Account freezes.
- Travel restrictions.
- Payment blacklisting.
- Credential revocation.

Each works by manipulating systems where you've already delegated control. The intermediary doesn't force you to do anything, it just denies you access to capabilities you thought you had.

Non-delegation is a design strategy to preserve degrees of freedom under institutional stress:

- **Self-custody** preserves the ability to transact without permission.
- **Encryption** preserves private communication without an administrator.
- **Portable identity and reputation** preserve exit without forfeiting accumulated social capital.

These aren't political preferences. They're mechanical defenses against dimensional compression by intermediaries, systems that may act in good faith under normal conditions, but that may become instruments of control when incentives shift, institutions fail, or power is captured.

## High-dimensional human systems.

Non-delegation is not merely defensive, it's also generative.

When individuals retain more degrees of freedom, the system as a whole can explore a larger state space: more experiments can run in parallel, more adaptations can emerge, and more solutions can be tested without requiring centralized permission or coordination.

This is why heavily regulated systems tend toward stagnation even without obvious corruption. It's not that every regulation is bad, but that each one constrains the possibility space. Over time, the accumulation of constraints reduces the system's dimensionality until only a narrow band of outcomes remains accessible, usually those that serve existing power structures.

High-dimensional human systems look different:

- **Multiple overlapping governance structures** rather than one monopoly. You can be subject to one system for dispute resolution, another for infrastructure, another for professional certification.
- **Low switching costs** between systems. Your identity, reputation, and social connections are portable. Exit is cheap.
- **Opt-in rather than geographically determined**. You choose which systems to participate in based on alignment, not accidents of birth.
- **Competition on dimensions that matter to users**. Systems compete to respect user intent, whether that's continuous attention, private communication, or financial autonomy, not to capture and extract from users.

Just as a hand with more joints can manipulate more objects than a rigid claw, a society with more institutional degrees of freedom can adapt to more challenges, serve more preferences, and survive more shocks.

The Enlightenment framework was an adaptation to a higher-dimensional world created by print. What comes next must be an adaptation to an even higher-dimensional world created by networks, cryptography, and AI.

The choice is between expanding the dimensionality of our institutions, making them capable of regulating without compressing, or watching them collapse reality back into something governable through the only tool low-dimensional controllers have left: force.

Degrees of freedom, in the end, are not just a physics concept or a political metaphor. They're the measure of what a system can become. And the systems that preserve more of them, in individuals, in institutions, in society, are the ones that survive contact with an increasingly complex world.

---

**Notes and Definitions:**

*Industrial Revolution*: The period of rapid industrialization from roughly 1760 to 1840, characterized by the transition from hand production methods to machines, new chemical and iron production processes, and the development of machine tools.

*Homeostasis*: The tendency of biological systems to maintain internal stability by regulating their internal environment, even as external conditions change. Examples include body temperature regulation and blood sugar control.

*Law of Requisite Variety*: Formulated by W. Ross Ashby in 1956, stating that for a regulatory system to successfully control another system, it must have at least as much internal variety (possible states/responses) as the system it's trying to regulate.